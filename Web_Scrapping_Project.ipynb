{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e0530-19e4-4fda-be48-9a12089c63a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "base_url = \"https://books.toscrape.com/\"\n",
    "\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"utf-8\"           # Fixing encoding issue\n",
    "    return BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "def clean_price(raw_price):\n",
    "    # Removing weird characters and currency symbol, keeping only digits and decimal\n",
    "    return re.sub(r\"[^\\d\\.]\", \"\", raw_price)\n",
    "\n",
    "def scrape_page(url):\n",
    "    soup = get_soup(url)\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "    page_data = []\n",
    "\n",
    "    for book in books:\n",
    "        title = book.h3.a[\"title\"]\n",
    "\n",
    "        raw_price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
    "        price = clean_price(raw_price)  # Cleaning numeric price\n",
    "\n",
    "        rating = book.p[\"class\"][1]  # star rating text\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "        link = base_url + book.h3.a[\"href\"]\n",
    "\n",
    "        page_data.append([title, price, rating, availability, link])\n",
    "\n",
    "    return page_data\n",
    "\n",
    "def scrape_all_books():\n",
    "    all_books = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        page_url = f\"{base_url}catalogue/page-{page}.html\"\n",
    "        response = requests.get(page_url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "\n",
    "        print(f\"Scraping page {page}...\")\n",
    "\n",
    "        all_books.extend(scrape_page(page_url))\n",
    "        page += 1\n",
    "\n",
    "    return all_books\n",
    "\n",
    "def save_to_csv(data):\n",
    "    with open(\"books_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Title\", \"Price\", \"Rating\", \"Availability\", \"Link\"])\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(\"Saved clean data to books.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_all_books()\n",
    "    save_to_csv(data)\n",
    "    print(f\"Scraped {len(data)} books successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d820fd8-ab7a-4e33-91cf-826f27e097b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5493259-95ab-4d3c-a9ff-362c465cb038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
